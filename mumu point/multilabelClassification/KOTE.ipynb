{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 HuggingFace Datasets Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Lint as: python3\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import datasets\n",
    "\n",
    "_CITATION = \"\"\"\\\n",
    "@article{jeon2022user,\n",
    "    title={User Guide for KOTE: Korean Online Comments Emotions Dataset},\n",
    "    author={Jeon, Duyoung and Lee, Junho and Kim, Cheongtag},\n",
    "    journal={arXiv preprint arXiv:2205.05300},\n",
    "    year={2022}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "_DESCRIPTION = \"\"\"\\\n",
    "50k Korean online comments labeled for 44 emotion categories.\n",
    "\"\"\"\n",
    "\n",
    "_HOMEPAGE = \"https://github.com/searle-j/KOTE\"\n",
    "\n",
    "_LICENSE = \"MIT License\"\n",
    "\n",
    "_BASE_URL = \"https://raw.githubusercontent.com/searle-j/KOTE/main/\"\n",
    "\n",
    "_LABELS = [\n",
    "'불평/불만',\n",
    "'환영/호의',\n",
    "'감동/감탄',\n",
    "'지긋지긋',\n",
    "'고마움',\n",
    "'슬픔',\n",
    "'화남/분노',\n",
    "'존경',\n",
    "'기대감',\n",
    "'우쭐댐/무시함',\n",
    "'안타까움/실망',\n",
    "'비장함',\n",
    "'의심/불신',\n",
    "'뿌듯함',\n",
    "'편안/쾌적',\n",
    "'신기함/관심',\n",
    "'아껴주는',\n",
    "'부끄러움',\n",
    "'공포/무서움',\n",
    "'절망',\n",
    "'한심함',\n",
    "'역겨움/징그러움',\n",
    "'짜증',\n",
    "'어이없음',\n",
    "'없음',\n",
    "'패배/자기혐오',\n",
    "'귀찮음',\n",
    "'힘듦/지침',\n",
    "'즐거움/신남',\n",
    "'깨달음',\n",
    "'죄책감',\n",
    "'증오/혐오',\n",
    "'흐뭇함(귀여움/예쁨)',\n",
    "'당황/난처',\n",
    "'경악',\n",
    "'부담/안_내킴',\n",
    "'서러움',\n",
    "'재미없음',\n",
    "'불쌍함/연민',\n",
    "'놀람',\n",
    "'행복',\n",
    "'불안/걱정',\n",
    "'기쁨',\n",
    "'안심/신뢰'\n",
    "]\n",
    "\n",
    "class KOTEConfig(datasets.BuilderConfig):\n",
    "    @property\n",
    "    def features(self):\n",
    "        if self.name == \"dichotomized\":\n",
    "            return {\n",
    "                \"ID\": datasets.Value(\"string\"),\n",
    "                \"text\": datasets.Value(\"string\"),\n",
    "                \"labels\": datasets.Sequence(datasets.ClassLabel(names=_LABELS)),\n",
    "            }\n",
    "\n",
    "class KOTE(datasets.GeneratorBasedBuilder):\n",
    "    BUILDER_CONFIGS = [KOTEConfig(name=\"dichotomized\")]\n",
    "    BUILDER_CONFIG_CLASS = KOTEConfig\n",
    "    DEFAULT_CONFIG_NAME = \"dichotomized\"\n",
    "    \n",
    "    def _info(self):\n",
    "        return datasets.DatasetInfo(\n",
    "            description=_DESCRIPTION,\n",
    "            features=datasets.Features(self.config.features),\n",
    "            homepage=_HOMEPAGE,\n",
    "            license=_LICENSE,\n",
    "            citation=_CITATION,\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def _split_generators(self, dl_manager):\n",
    "        if self.config.name==\"dichotomized\":\n",
    "            train_path = dl_manager.download_and_extract(os.path.join(_BASE_URL, \"train.tsv\"))\n",
    "            test_path = dl_manager.download_and_extract(os.path.join(_BASE_URL, \"test.tsv\"))\n",
    "            val_path = dl_manager.download_and_extract(os.path.join(_BASE_URL, \"val.tsv\"))\n",
    "            return [\n",
    "                datasets.SplitGenerator(name=datasets.Split.TRAIN, gen_kwargs={\"filepaths\": [train_path],}),\n",
    "                datasets.SplitGenerator(name=datasets.Split.TEST, gen_kwargs={\"filepaths\": [test_path],}),\n",
    "                datasets.SplitGenerator(name=datasets.Split.VALIDATION, gen_kwargs={\"filepaths\": [val_path],}),\n",
    "            ]\n",
    "            \n",
    "    def _generate_examples(self, filepaths):\n",
    "        if self.config.name==\"dichotomized\":\n",
    "            for filepath in filepaths:\n",
    "                with open(filepath, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "                    reader = csv.DictReader(f, delimiter=\"\\t\", fieldnames=list(self.config.features.keys()))\n",
    "                    for idx, row in enumerate(reader):\n",
    "                        row[\"labels\"] = [int(lab) for lab in row[\"labels\"].split(\",\")]\n",
    "                        yield idx, row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (4.67.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.11.8)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.26.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['ID', 'text', 'labels'],\n",
      "        num_rows: 40000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['ID', 'text', 'labels'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['ID', 'text', 'labels'],\n",
      "        num_rows: 5000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# KOTE 데이터셋 로드\n",
    "dataset = load_dataset(\"searle-j/kote\", trust_remote_code=True)\n",
    "\n",
    "# 데이터셋 정보 출력\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"].to_pandas().to_csv(\"kote_train.csv\", index=False)\n",
    "dataset[\"test\"].to_pandas().to_csv(\"kote_test.csv\", index=False)\n",
    "dataset[\"validation\"].to_pandas().to_csv(\"kote_validation.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_22096\\1546724852.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(r\"C:/Users/Playdata/Desktop/Final/model/KOTE/kote_pytorch_lightning.bin\", map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감동/감탄: 0.9351656436920166\n",
      "존경: 0.7400605082511902\n",
      "신기함/관심: 0.5662599802017212\n",
      "깨달음: 0.49894675612449646\n",
      "놀람: 0.49727797508239746\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "from transformers import ElectraModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "LABELS = ['불평/불만',\n",
    " '환영/호의',\n",
    " '감동/감탄',\n",
    " '지긋지긋',\n",
    " '고마움',\n",
    " '슬픔',\n",
    " '화남/분노',\n",
    " '존경',\n",
    " '기대감',\n",
    " '우쭐댐/무시함',\n",
    " '안타까움/실망',\n",
    " '비장함',\n",
    " '의심/불신',\n",
    " '뿌듯함',\n",
    " '편안/쾌적',\n",
    " '신기함/관심',\n",
    " '아껴주는',\n",
    " '부끄러움',\n",
    " '공포/무서움',\n",
    " '절망',\n",
    " '한심함',\n",
    " '역겨움/징그러움',\n",
    " '짜증',\n",
    " '어이없음',\n",
    " '없음',\n",
    " '패배/자기혐오',\n",
    " '귀찮음',\n",
    " '힘듦/지침',\n",
    " '즐거움/신남',\n",
    " '깨달음',\n",
    " '죄책감',\n",
    " '증오/혐오',\n",
    " '흐뭇함(귀여움/예쁨)',\n",
    " '당황/난처',\n",
    " '경악',\n",
    " '부담/안_내킴',\n",
    " '서러움',\n",
    " '재미없음',\n",
    " '불쌍함/연민',\n",
    " '놀람',\n",
    " '행복',\n",
    " '불안/걱정',\n",
    " '기쁨',\n",
    " '안심/신뢰']\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class KOTEtagger(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.electra = ElectraModel.from_pretrained(\"beomi/KcELECTRA-base\", revision='v2021').to(device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\", revision='v2021')\n",
    "        self.classifier = nn.Linear(self.electra.config.hidden_size, 44).to(device)\n",
    "        \n",
    "    def forward(self, text:str):\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "          text,\n",
    "          add_special_tokens=True,\n",
    "          max_length=512,\n",
    "          return_token_type_ids=False,\n",
    "          padding=\"max_length\",\n",
    "          return_attention_mask=True,\n",
    "          return_tensors='pt',\n",
    "        ).to(device)\n",
    "        output = self.electra(encoding[\"input_ids\"], attention_mask=encoding[\"attention_mask\"])\n",
    "        output = output.last_hidden_state[:,0,:]\n",
    "        output = self.classifier(output)\n",
    "        output = torch.sigmoid(output)\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return output\n",
    "\n",
    "# 모델 초기화\n",
    "trained_model = KOTEtagger()\n",
    "\n",
    "# 모델 가중치 로드 (strict=False 적용)\n",
    "state_dict = torch.load(r\"C:/Users/Playdata/Desktop/Final/model/KOTE/kote_pytorch_lightning.bin\", map_location=device)\n",
    "trained_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "preds = trained_model(\n",
    "\"\"\"인셉션은 대단하다고 느꼈는데, 인터스텔라는 경이롭다고 느껴진다다\"\"\"\n",
    ")[0]\n",
    "\n",
    "for l, p in zip(LABELS, preds):\n",
    "    if p>0.4:\n",
    "        print(f\"{l}: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_37984\\3206259535.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(r\"C:/Users/Playdata/Desktop/Final/model/KOTE/kote_pytorch_lightning.bin\", map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감정 분석 결과가 저장되었습니다: C:/Users/Playdata/Desktop/Final/model/KOTE/emotion_analysis.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "from transformers import ElectraModel, AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "LABELS = [\n",
    "    '불평/불만', '환영/호의', '감동/감탄', '지긋지긋', '고마움', '슬픔', '화남/분노', '존경', '기대감', '우쭐댐/무시함',\n",
    "    '안타까움/실망', '비장함', '의심/불신', '뿌듯함', '편안/쾌적', '신기함/관심', '아껴주는', '부끄러움', '공포/무서움', '절망',\n",
    "    '한심함', '역겨움/징그러움', '짜증', '어이없음', '없음', '패배/자기혐오', '귀찮음', '힘듦/지침', '즐거움/신남', '깨달음',\n",
    "    '죄책감', '증오/혐오', '흐뭇함(귀여움/예쁨)', '당황/난처', '경악', '부담/안_내킴', '서러움', '재미없음', '불쌍함/연민',\n",
    "    '놀람', '행복', '불안/걱정', '기쁨', '안심/신뢰'\n",
    "]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class KOTEtagger(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.electra = ElectraModel.from_pretrained(\"beomi/KcELECTRA-base\", revision='v2021').to(device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\", revision='v2021')\n",
    "        self.classifier = nn.Linear(self.electra.config.hidden_size, len(LABELS)).to(device)\n",
    "        \n",
    "    def forward(self, text: str):\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        ).to(device)\n",
    "        \n",
    "        output = self.electra(encoding[\"input_ids\"], attention_mask=encoding[\"attention_mask\"])\n",
    "        output = output.last_hidden_state[:, 0, :]\n",
    "        output = self.classifier(output)\n",
    "        output = torch.sigmoid(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# 모델 초기화\n",
    "trained_model = KOTEtagger()\n",
    "\n",
    "# 모델 가중치 로드 (strict=False 적용)\n",
    "state_dict = torch.load(r\"C:/Users/Playdata/Desktop/Final/model/KOTE/kote_pytorch_lightning.bin\", map_location=device)\n",
    "trained_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "# 엑셀 데이터 로드\n",
    "data_path = r\"C:/Users/Playdata/Desktop/Final/model/calculation/1stcalculationtest.xlsx\"  # 파일 경로 지정\n",
    "df = pd.read_excel(data_path)\n",
    "\n",
    "# 첫 번째 영화의 제목 및 리뷰 가져오기\n",
    "movie_title = df.columns[0]  # 첫 번째 행(영화 제목)\n",
    "reviews = df[movie_title].dropna().tolist()[:150]  # 최대 150개 리뷰 선택\n",
    "\n",
    "# 감정 분석 실행\n",
    "results = []\n",
    "for review in reviews:\n",
    "    preds = trained_model(review)[0].detach().cpu().numpy()\n",
    "    result = {\"리뷰\": review}\n",
    "    \n",
    "    # 감정 점수가 0.4 이상인 것만 필터링 후, 상위 10개 감정 선택\n",
    "    filtered_emotions = [(label, score) for label, score in zip(LABELS, preds) if score >= 0.4]\n",
    "    top_10_emotions = sorted(filtered_emotions, key=lambda x: x[1], reverse=True)[:10]\n",
    "    \n",
    "    for label, score in top_10_emotions:\n",
    "        result[label] = score\n",
    "    \n",
    "    results.append(result)\n",
    "\n",
    "# 결과를 데이터프레임으로 변환 및 엑셀 저장\n",
    "result_df = pd.DataFrame(results)\n",
    "output_path = \"C:/Users/Playdata/Desktop/Final/model/calculation/emotion_analysis.xlsx\"\n",
    "result_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"감정 분석 결과가 저장되었습니다: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_3964\\1142653364.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(r\"C:/Users/Playdata/Desktop/Final/model/KOTE/kote_pytorch_lightning.bin\", map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감정 분석 결과가 저장되었습니다: C:/Users/Playdata/Desktop/Final/model/calculation/emotion_analysis.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "from transformers import ElectraModel, AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "LABELS = [\n",
    "    '불평/불만', '환영/호의', '감동/감탄', '지긋지긋', '고마움', '슬픔', '화남/분노', '존경', '기대감', '우쭐댐/무시함',\n",
    "    '안타까움/실망', '비장함', '의심/불신', '뿌듯함', '편안/쾌적', '신기함/관심', '아껴주는', '부끄러움', '공포/무서움', '절망',\n",
    "    '한심함', '역겨움/징그러움', '짜증', '어이없음', '없음', '패배/자기혐오', '귀찮음', '힘듦/지침', '즐거움/신남', '깨달음',\n",
    "    '죄책감', '증오/혐오', '흐뭇함(귀여움/예쁨)', '당황/난처', '경악', '부담/안_내킴', '서러움', '재미없음', '불쌍함/연민',\n",
    "    '놀람', '행복', '불안/걱정', '기쁨', '안심/신뢰'\n",
    "]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class KOTEtagger(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.electra = ElectraModel.from_pretrained(\"beomi/KcELECTRA-base\", revision='v2021').to(device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\", revision='v2021')\n",
    "        self.classifier = nn.Linear(self.electra.config.hidden_size, len(LABELS)).to(device)\n",
    "        \n",
    "    def forward(self, text: str):\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        ).to(device)\n",
    "        \n",
    "        output = self.electra(encoding[\"input_ids\"], attention_mask=encoding[\"attention_mask\"])\n",
    "        output = output.last_hidden_state[:, 0, :]\n",
    "        output = self.classifier(output)\n",
    "        output = torch.sigmoid(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# 모델 초기화 및 가중치 로드\n",
    "trained_model = KOTEtagger()\n",
    "state_dict = torch.load(r\"C:/Users/Playdata/Desktop/Final/model/KOTE/kote_pytorch_lightning.bin\", map_location=device)\n",
    "trained_model.load_state_dict(state_dict, strict=False)\n",
    "trained_model.eval()  # 평가 모드 전환\n",
    "\n",
    "# 엑셀 데이터 로드 (각 열은 영화 제목, 각 열 아래에는 최대 150개의 리뷰가 저장되어 있음)\n",
    "data_path = r\"C:/Users/Playdata/Desktop/Final/model/calculation/1stcalculationtest.xlsx\"\n",
    "df = pd.read_excel(data_path)\n",
    "\n",
    "# 각 영화(열)별로 새로운 emotion_point 열을 생성\n",
    "# 각 영화의 리뷰에 대해 상위 2개의 예측값(0.4 이상의 값이 있다면 그 중 상위 2, 없으면 전체에서 상위 2)을 평균 내어 emotion_point로 산출\n",
    "emotion_threshold = 0.4\n",
    "\n",
    "# torch.no_grad()를 사용하여 gradient 계산 없이 추론 수행\n",
    "with torch.no_grad():\n",
    "    for movie in df.columns:\n",
    "        # 리뷰별 emotion_point를 저장할 리스트\n",
    "        emotion_points = []\n",
    "        # 각 리뷰에 대해 처리 (NaN이면 그대로 NaN)\n",
    "        for review in df[movie]:\n",
    "            if pd.isna(review):\n",
    "                emotion_points.append(np.nan)\n",
    "            else:\n",
    "                preds = trained_model(review)[0].detach().cpu().numpy()\n",
    "                # threshold 이상의 감정만 선택\n",
    "                filtered = [score for score in preds if score >= emotion_threshold]\n",
    "                if len(filtered) >= 2:\n",
    "                    top_two = sorted(filtered, reverse=True)[:2]\n",
    "                    point = sum(top_two) / 2.0\n",
    "                elif len(filtered) == 1:\n",
    "                    point = filtered[0]\n",
    "                else:\n",
    "                    # threshold를 만족하는 감정이 없을 경우, 전체에서 상위 2개 선택\n",
    "                    top_two = sorted(preds, reverse=True)[:2]\n",
    "                    # 모델 출력은 항상 45개 값이므로 top_two는 항상 2개 이상일 것임\n",
    "                    point = sum(top_two) / 2.0\n",
    "                emotion_points.append(point)\n",
    "        # 새로운 열 이름은 \"{영화제목}_emotion_point\"\n",
    "        new_col_name = f\"{movie}_emotion_point\"\n",
    "        df[new_col_name] = emotion_points\n",
    "\n",
    "# 새로운 엑셀 파일로 저장\n",
    "output_path = r\"C:/Users/Playdata/Desktop/Final/model/calculation/emotion_analysis.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"감정 분석 결과가 저장되었습니다: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
